{"cells":[{"cell_type":"markdown","source":["# **Triangle Judgement**\n","\n","## **Problem Statement**\n","You are given a table **Triangle** with the following structure:\n","\n","### **Table: Triangle**\n","| Column Name | Type |\n","|------------|------|\n","| `x`        | int  |\n","| `y`        | int  |\n","| `z`        | int  |\n","\n","### **Objective**\n","Write a query to determine whether three given side lengths can form a valid triangle.\n","\n","### **Triangle Formation Condition**\n","A triangle is **valid** if it satisfies the **triangle inequality theorem**:\n","\\[\n","x + y > z, \\quad x + z > y, \\quad y + z > x\n","\\]\n","Otherwise, it is **not a triangle**.\n","\n","---\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4ee8e690-4f53-415d-9db7-c8a455331ad9"},{"cell_type":"markdown","source":["\n","## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**\n","2. **Create a DataFrame for `Triangle` Table**\n","3. **Apply Triangle Inequality Conditions**\n","4. **Add a New Column `triangle` to Store \"Yes\" or \"No\"**\n","5. **Display the Result**\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e5372d94-8faf-4d3d-9327-1eb3f474ece3"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import when, col\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"TriangleJudgement\").getOrCreate()\n","\n","# Step 2: Create DataFrame for Triangle Table\n","triangle_data = [(13, 15, 30), (10, 20, 15)]\n","triangle_columns = [\"x\", \"y\", \"z\"]\n","\n","triangle_df = spark.createDataFrame(triangle_data, triangle_columns)\n","\n","# Step 3: Apply Triangle Inequality Conditions\n","triangle_df = triangle_df.withColumn(\n","    \"triangle\",\n","    when((col(\"x\") + col(\"y\") > col(\"z\")) & \n","         (col(\"x\") + col(\"z\") > col(\"y\")) & \n","         (col(\"y\") + col(\"z\") > col(\"x\")), \"Yes\").otherwise(\"No\")\n",")\n","\n","# Step 4: Display Result\n","triangle_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"d120f75f-3c0d-42e7-bf3f-24a8a1dbdac0","normalized_state":"finished","queued_time":"2025-03-22T15:36:08.0304528Z","session_start_time":null,"execution_start_time":"2025-03-22T15:36:08.032092Z","execution_finish_time":"2025-03-22T15:36:08.8600622Z","parent_msg_id":"6d74924e-8742-4a2d-a05d-0eddee3f596f"},"text/plain":"StatementMeta(, d120f75f-3c0d-42e7-bf3f-24a8a1dbdac0, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+---+---+--------+\n|  x|  y|  z|triangle|\n+---+---+---+--------+\n| 13| 15| 30|      No|\n| 10| 20| 15|     Yes|\n+---+---+---+--------+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d4a49a40-70d1-4958-9931-8e3470f32e1e"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Create Spark Session**\n","2. **Create DataFrame for `Triangle` Table**\n","3. **Register it as a SQL View**\n","4. **Write and Execute SQL Query**\n","5. **Display the Output**\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1a6be53a-a259-4396-86ab-da4cf956e123"},{"cell_type":"code","source":["# Step 1: Register DataFrame as a SQL View\n","triangle_df.createOrReplaceTempView(\"Triangle\")\n","\n","# Step 2: Run SQL Query\n","sql_query = \"\"\"\n","SELECT x, y, z,\n","       CASE \n","           WHEN (x + y > z) AND (x + z > y) AND (y + z > x) THEN 'Yes'\n","           ELSE 'No'\n","       END AS triangle\n","FROM Triangle;\n","\"\"\"\n","\n","result_sql = spark.sql(sql_query)\n","\n","# Step 3: Display Output\n","result_sql.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"d120f75f-3c0d-42e7-bf3f-24a8a1dbdac0","normalized_state":"finished","queued_time":"2025-03-22T15:36:08.2453282Z","session_start_time":null,"execution_start_time":"2025-03-22T15:36:08.862845Z","execution_finish_time":"2025-03-22T15:36:10.3818398Z","parent_msg_id":"06ce92c3-764a-4f91-a83f-f7167411bd02"},"text/plain":"StatementMeta(, d120f75f-3c0d-42e7-bf3f-24a8a1dbdac0, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+---+---+--------+\n|  x|  y|  z|triangle|\n+---+---+---+--------+\n| 13| 15| 30|      No|\n| 10| 20| 15|     Yes|\n+---+---+---+--------+\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e8adc787-a76b-4316-b5b1-166df68c923a"},{"cell_type":"markdown","source":["\n","---\n","\n","## **Summary**\n","| Approach  | Method                      | Steps  |\n","|-----------|-----------------------------|--------|\n","| **Approach 1** | PySpark DataFrame API    | Uses `when()` and `withColumn()` |\n","| **Approach 2** | SQL Query in PySpark     | Uses `CASE WHEN` condition |"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"fb831d14-8d00-4976-8b94-1e2059708fdc"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}