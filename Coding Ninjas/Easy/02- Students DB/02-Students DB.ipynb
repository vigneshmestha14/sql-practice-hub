{"cells":[{"cell_type":"markdown","source":["# **Students DB**\n","\n","## **Problem Statement**\n","Insert the following student details into the `students` table and print all data from the table.\n","\n","### **Student Data to Insert:**\n","| ID  | Name   | Gender |\n","|-----|--------|--------|\n","| 3   | Kim    | F      |\n","| 4   | Molina | F      |\n","| 5   | Dev    | M      |\n","\n","\n","## **Notes**\n","- Ensure the `students` table exists before running the query.\n","- Verify that ID is a unique primary key.\n","- Modify column names if needed to match the table schema."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e5e4bd88-80ee-4540-976c-1ec282a1698f"},{"cell_type":"markdown","source":["## **Approach 1: Using PySpark DataFrame API**\n","Instead of executing SQL, we use PySpark's DataFrame API to create and insert data.\n","\n","### **Steps**  \n","1. Create a `students` table if it does not exist.  \n","2. Insert the given student records into the table.  \n","3. Fetch and display all records."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5ee6d1fd-e322-410e-85e3-dda5652c480c"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName(\"StudentDataInsert\").getOrCreate()\n","\n","# Define schema for the DataFrame\n","schema = StructType([\n","    StructField(\"ID\", IntegerType(), False),\n","    StructField(\"Name\", StringType(), False),\n","    StructField(\"Gender\", StringType(), False)\n","])\n","\n","# Create a DataFrame with student data\n","students_data = [\n","    (3, \"Kim\", \"F\"),\n","    (4, \"Molina\", \"F\"),\n","    (5, \"Dev\", \"M\")\n","]\n","\n","students_df = spark.createDataFrame(students_data, schema)\n","\n","# Show DataFrame contents\n","students_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"447cff80-f0cc-44de-aedd-ea18b424b10b","normalized_state":"finished","queued_time":"2025-03-13T15:45:19.8850325Z","session_start_time":"2025-03-13T15:45:19.8864654Z","execution_start_time":"2025-03-13T15:45:38.6572007Z","execution_finish_time":"2025-03-13T15:45:42.5568885Z","parent_msg_id":"83c4d2b3-eafc-45fb-b7c8-859722d43d9e"},"text/plain":"StatementMeta(, 447cff80-f0cc-44de-aedd-ea18b424b10b, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+------+------+\n| ID|  Name|Gender|\n+---+------+------+\n|  3|   Kim|     F|\n|  4|Molina|     F|\n|  5|   Dev|     M|\n+---+------+------+\n\n"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2a6c37c1-5a08-4739-8116-9b2c12ffafce"},{"cell_type":"markdown","source":["## **Approach 2: SQL Query in PySpark**\n","In this approach, we execute SQL queries directly within PySpark.\n","\n","### **Steps**  \n","1. Define `student` data as a DataFrame.   \n","2. Display all records."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7e2a8ea9-d6b6-4a94-b7dc-04e3e9a8e4f3"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName(\"StudentDataInsert\").config(\"spark.sql.catalogImplementation\",\"in-memory\").getOrCreate()\n","\n","# Create a temporary table (if not exists)\n","spark.sql(\"\"\"\n","    CREATE TABLE IF NOT EXISTS students (\n","        ID INT,\n","        Name STRING,\n","        Gender STRING\n","    )\n","\"\"\")\n","\n","# Insert data into the table\n","spark.sql(\"INSERT INTO students VALUES (3, 'Kim', 'F')\")\n","spark.sql(\"INSERT INTO students VALUES (4, 'Molina', 'F')\")\n","spark.sql(\"INSERT INTO students VALUES (5, 'Dev', 'M')\")\n","\n","# Retrieve and display all data\n","students_df = spark.sql(\"SELECT * FROM students\")\n","students_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"447cff80-f0cc-44de-aedd-ea18b424b10b","normalized_state":"finished","queued_time":"2025-03-13T15:45:19.8868699Z","session_start_time":null,"execution_start_time":"2025-03-13T15:45:42.5596411Z","execution_finish_time":"2025-03-13T15:46:11.9049403Z","parent_msg_id":"3786e562-be63-4042-8ace-26eaf6d5e393"},"text/plain":"StatementMeta(, 447cff80-f0cc-44de-aedd-ea18b424b10b, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+------+------+\n| ID|  Name|Gender|\n+---+------+------+\n|  4|Molina|     F|\n|  5|   Dev|     M|\n|  3|   Kim|     F|\n+---+------+------+\n\n"]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"44ba5ff1-1279-4c38-b623-9cbd2e428088"},{"cell_type":"markdown","source":["### **Key Differences**\n","| Approach | Uses SQL Queries | Uses DataFrame API | Suitable for Large Data |\n","|----------|----------------|--------------------|----------------------|\n","| **SQL in PySpark** | ‚úÖ | ‚ùå | ‚úÖ |\n","| **DataFrame API** | ‚ùå | ‚úÖ | ‚úÖ |\n","\n","Both approaches are valid; choose the one that best suits your use case. Let me know if you need modifications! üöÄ"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8c680071-8655-4161-96ff-9e4a62fcefbd"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"1f4688c4-9112-42ba-8c5a-2c7045d78522","default_lakehouse_name":"lh_sql_practice_hub","default_lakehouse_workspace_id":"c6598bd0-bf59-4b02-a761-73171d8c2571"}}},"nbformat":4,"nbformat_minor":5}