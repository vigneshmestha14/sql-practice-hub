{"cells":[{"cell_type":"markdown","source":["# **Swap Salary**\n","\n","## **Problem Statement**\n","Given a table `Salary`:\n","\n","| Column Name | Type    |\n","|-------------|--------|\n","| `id`        | int    |\n","| `name`      | varchar |\n","| `sex`       | ENUM('m', 'f') |\n","| `salary`    | int    |\n","\n","- `id` is the **primary key**.\n","- The `sex` column contains values `'m'` (male) or `'f'` (female).\n","- The table contains **employee salary details**.\n","\n","### **Task**\n","Write a **query** to swap all `'m'` and `'f'` values in the `sex` column.\n","\n","---\n","\n","## **Example**\n","\n","### **Input:**\n","**Salary Table**\n","| id | name  | sex | salary |\n","|----|------|-----|--------|\n","| 1  | Alex | 'm' | 5000   |\n","| 2  | Eve  | 'f' | 7000   |\n","| 3  | Sam  | 'm' | 8000   |\n","| 4  | Mia  | 'f' | 7500   |\n","\n","### **Output:**\n","| id | name  | sex | salary |\n","|----|------|-----|--------|\n","| 1  | Alex | 'f' | 5000   |\n","| 2  | Eve  | 'm' | 7000   |\n","| 3  | Sam  | 'f' | 8000   |\n","| 4  | Mia  | 'm' | 7500   |\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2ddca5c7-d884-4ff1-a4bf-63ff4720f294"},{"cell_type":"markdown","source":["\n","## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**  \n","   - Create a Spark session to work with PySpark.\n","2. **Load Data**  \n","   - Read the dataset `Salary.csv` into a PySpark DataFrame.\n","3. **Use `when()` and `col()` to swap 'm' and 'f'**  \n","   - Use `F.when()` to **replace** 'm' with 'f' and vice versa.\n","4. **Select and Display Output**  \n","   - Show the updated DataFrame.\n","\n","### **Code**\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"aae5960c-34cf-498d-a09c-aec89c5b7310"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, when\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"SwapSalary\").getOrCreate()\n","\n","# Step 2: Create a Sample Dataset\n","data = [\n","    (1, \"Alex\", \"m\", 5000),\n","    (2, \"Eve\", \"f\", 7000),\n","    (3, \"Sam\", \"m\", 8000),\n","    (4, \"Mia\", \"f\", 7500)\n","]\n","columns = [\"id\", \"name\", \"sex\", \"salary\"]\n","\n","# Step 3: Create DataFrame\n","salary_df = spark.createDataFrame(data, schema=columns)\n","\n","# Step 4: Swap 'm' with 'f' and vice versa\n","swapped_df = salary_df.withColumn(\n","    \"sex\",\n","    when(col(\"sex\") == \"m\", \"f\").when(col(\"sex\") == \"f\", \"m\").otherwise(col(\"sex\"))\n",")\n","\n","# Step 5: Display the Output\n","swapped_df.show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"dc35663e-1e54-4ba5-8941-3f2bbe5d0222","normalized_state":"finished","queued_time":"2025-03-16T14:25:49.4472964Z","session_start_time":null,"execution_start_time":"2025-03-16T14:25:49.4489816Z","execution_finish_time":"2025-03-16T14:25:54.0342265Z","parent_msg_id":"55b4a109-6919-4207-a77a-51b08ff6e3d4"},"text/plain":"StatementMeta(, dc35663e-1e54-4ba5-8941-3f2bbe5d0222, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+----+---+------+\n| id|name|sex|salary|\n+---+----+---+------+\n|  1|Alex|  f|  5000|\n|  2| Eve|  m|  7000|\n|  3| Sam|  f|  8000|\n|  4| Mia|  m|  7500|\n+---+----+---+------+\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9696fab8-1d9b-47c5-b513-9bf7ca447796"},{"cell_type":"markdown","source":["\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Initialize Spark Session**  \n","   - Create a Spark session.\n","2. **Load Data and Create DataFrame**  \n","   - Read `Salary.csv` into a PySpark DataFrame.\n","3. **Create a Temporary SQL View**  \n","   - Register the DataFrame as a **temporary SQL table**.\n","4. **Write and Execute SQL Query**  \n","   - Use `CASE` statement to **swap 'm' with 'f'** and vice versa.\n","5. **Show Results**  \n","   - Execute the query and display the output.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3247dbb3-4983-4481-9702-e13282d317c3"},{"cell_type":"code","source":["# Step 1-3: Create Temporary View\n","salary_df.createOrReplaceTempView(\"Salary\")\n","\n","# Step 4: Run SQL Query\n","query = \"\"\"\n","SELECT id, name, \n","       CASE \n","           WHEN sex = 'm' THEN 'f' \n","           WHEN sex = 'f' THEN 'm' \n","           ELSE sex \n","       END AS sex, \n","       salary\n","FROM Salary\n","\"\"\"\n","\n","# Step 5: Execute SQL Query\n","sql_result = spark.sql(query)\n","\n","# Step 6: Show Output\n","sql_result.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"dc35663e-1e54-4ba5-8941-3f2bbe5d0222","normalized_state":"finished","queued_time":"2025-03-16T14:27:20.8832652Z","session_start_time":null,"execution_start_time":"2025-03-16T14:27:20.8849662Z","execution_finish_time":"2025-03-16T14:27:34.5436431Z","parent_msg_id":"92fe1385-97c2-4058-b8c5-1173b53544e5"},"text/plain":"StatementMeta(, dc35663e-1e54-4ba5-8941-3f2bbe5d0222, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+----+---+------+\n| id|name|sex|salary|\n+---+----+---+------+\n|  1|Alex|  f|  5000|\n|  2| Eve|  m|  7000|\n|  3| Sam|  f|  8000|\n|  4| Mia|  m|  7500|\n+---+----+---+------+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"46aa59f2-c0be-4f27-9fd3-5bcb2e59e8b2"},{"cell_type":"markdown","source":["## **Summary**\n","| Approach | Method | Steps |\n","|----------|--------|-------|\n","| **Approach 1** | PySpark DataFrame API | Uses `when()` and `col()` to swap values |\n","| **Approach 2** | SQL Query in PySpark | Uses `CASE` statement in SQL |"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ead29921-a677-4ac1-89ff-1e83d3e6ed95"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}