{"cells":[{"cell_type":"markdown","source":["# **Director's Actor**\n","\n","## **Problem Statement**\n","Given a table `ActorDirector`:\n","\n","| Column Name  | Type  |\n","|-------------|-------|\n","| `actor_id`  | int   |\n","| `director_id` | int   |\n","| `timestamp`  | int   |\n","\n","- `timestamp` is the **primary key** of this table.\n","- Write a **SQL query** to output pairs **(actor_id, director_id)** where the actor has worked with the director **at least 3 times**.\n","\n","### **Example**\n","\n","#### **Input:**\n","**ActorDirector Table**\n","| actor_id | director_id | timestamp |\n","|----------|------------|-----------|\n","| 1        | 1          | 0         |\n","| 1        | 1          | 1         |\n","| 1        | 1          | 2         |\n","| 1        | 2          | 3         |\n","| 1        | 2          | 4         |\n","| 2        | 1          | 5         |\n","| 2        | 1          | 6         |\n","\n","#### **Output:**\n","| actor_id | director_id |\n","|----------|------------|\n","| 1        | 1          |\n","\n","- The only valid pair is **(1,1)** because they co-worked **exactly 3 times**."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ba5eae5e-4041-444e-a387-a9e554da87c3"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**  \n","   - Create a Spark session to work with PySpark.\n","2. **Load Data**  \n","   - Read the dataset `ActorDirector.csv` into a PySpark DataFrame.\n","3. **Group by Actor-Director Pair**  \n","   - Use `groupBy(\"actor_id\", \"director_id\")` and count the occurrences.\n","4. **Filter for at least 3 occurrences**  \n","   - Apply `.filter(count >= 3)`.\n","5. **Select and Display Output**  \n","   - Show the final DataFrame.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b137c783-2718-4dbc-8617-0715302449e8"},{"cell_type":"code","source":["\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, count\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"DirectorActor\").getOrCreate()\n","\n","# Step 2: Create the DataFrame\n","data = [\n","    (1, 1, 0),\n","    (1, 1, 1),\n","    (1, 1, 2),\n","    (1, 2, 3),\n","    (1, 2, 4),\n","    (2, 1, 5),\n","    (2, 1, 6)\n","]\n","\n","# Create the DataFrame\n","actor_director_df = spark.createDataFrame(data, [\"actor_id\",\"director_id\",\"timestamp\"])\n","\n","# Step 3: Group by Actor and Director & Count Occurrences\n","grouped_df = actor_director_df.groupBy(\"actor_id\", \"director_id\").agg(count(\"*\").alias(\"count\"))\n","\n","# Step 4: Filter for pairs where count >= 3\n","filtered_df = grouped_df.filter(col(\"count\") >= 3).select(\"actor_id\", \"director_id\")\n","\n","# Step 5: Display the Output\n","filtered_df.show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"3bc0a491-7d64-4d6d-b0b9-0e20bd00ede4","normalized_state":"finished","queued_time":"2025-03-15T17:11:32.9088843Z","session_start_time":null,"execution_start_time":"2025-03-15T17:11:32.9104729Z","execution_finish_time":"2025-03-15T17:11:48.7751664Z","parent_msg_id":"b2989d17-4202-48b0-bbd1-fb12ad9c7000"},"text/plain":"StatementMeta(, 3bc0a491-7d64-4d6d-b0b9-0e20bd00ede4, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------+-----------+\n|actor_id|director_id|\n+--------+-----------+\n|       1|          1|\n+--------+-----------+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"03ff9296-2de6-4b2b-b150-8ae8d0152893"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Initialize Spark Session**  \n","   - Create a Spark session.\n","2. **Load Data and Create DataFrame**  \n","   - Read `ActorDirector.csv` into a PySpark DataFrame.\n","3. **Create a Temporary SQL View**  \n","   - Register the DataFrame as a **temporary SQL table**.\n","4. **Write and Execute SQL Query**  \n","   - **Group by** `actor_id`, `director_id`.\n","   - Use `COUNT(*) >= 3` to filter valid pairs.\n","5. **Show Results**  \n","   - Execute the query and display the output.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"db800e41-d353-459e-951c-983b483857fd"},{"cell_type":"code","source":["# Step 1-3: Create Temporary View\n","actor_director_df.createOrReplaceTempView(\"ActorDirector\")\n","\n","# Step 4: Run SQL Query\n","query = \"\"\"\n","SELECT actor_id, director_id\n","FROM ActorDirector\n","GROUP BY actor_id, director_id\n","HAVING COUNT(*) >= 3\n","\"\"\"\n","\n","# Step 5: Execute SQL Query\n","sql_result = spark.sql(query)\n","\n","# Step 6: Show Output\n","sql_result.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"3bc0a491-7d64-4d6d-b0b9-0e20bd00ede4","normalized_state":"finished","queued_time":"2025-03-15T17:11:33.1226959Z","session_start_time":null,"execution_start_time":"2025-03-15T17:11:48.7778621Z","execution_finish_time":"2025-03-15T17:11:49.5998999Z","parent_msg_id":"3c5bbd23-5c72-4d2a-9e9a-f4612cbb2773"},"text/plain":"StatementMeta(, 3bc0a491-7d64-4d6d-b0b9-0e20bd00ede4, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------+-----------+\n|actor_id|director_id|\n+--------+-----------+\n|       1|          1|\n+--------+-----------+\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8297c6a5-a08a-4c09-9a4a-a57b730f6623"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","| Approach | Method | Steps |\n","|----------|--------|-------|\n","| **Approach 1** | PySpark DataFrame API | Uses `groupBy()`, `agg(count)`, and `filter()` |\n","| **Approach 2** | SQL Query in PySpark | Uses `GROUP BY`, `HAVING COUNT(*) >= 3` |\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5d147664-7bc0-4f8c-8a29-42865b3f41b0"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}