{"cells":[{"cell_type":"markdown","source":["\n","# **Orders With Maximum Quantity Above Average**\n","\n","## **Problem Statement**\n","You are given a table **OrdersDetails** with the following structure:\n","\n","### **Table: OrdersDetails**\n","| Column Name | Type |\n","|------------|------|\n","| `order_id` | int  |\n","| `product_id` | int  |\n","| `quantity` | int  |\n","\n","### **Objective**\n","Find all `order_id` values where the **maximum quantity of a product** in the order is **strictly greater** than the **average quantity of all orders**.\n","\n","### **Definitions**\n","- **Order's Average Quantity** = (Total quantity in the order) / (Number of different products in the order)\n","- **Order's Maximum Quantity** = The highest `quantity` in the order\n","- **Imbalanced Order Condition**:\n","  \\[\n","  \\{max(quantity) of order} >{average quantity of all orders}\n","  \\]\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"fa0ade80-9320-4a2f-953a-5a49e13a0feb"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import avg, max, col, count, sum\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"ImbalancedOrders\").getOrCreate()\n","\n","# Step 2: Create DataFrame for OrdersDetails Table\n","orders_data = [\n","    (1, 1, 12), (1, 2, 10), (1, 3, 15),\n","    (2, 1, 8), (2, 4, 4), (2, 5, 6), (2, 9, 4),\n","    (3, 3, 5), (3, 4, 18), (3, 9, 20),\n","    (4, 5, 2), (4, 6, 8),\n","    (5, 7, 9), (5, 8, 9)\n","]\n","orders_columns = [\"order_id\", \"product_id\", \"quantity\"]\n","\n","orders_df = spark.createDataFrame(orders_data, orders_columns)\n","\n","# Step 3: Compute Average Quantity for Each Order\n","order_avg_df = orders_df.groupBy(\"order_id\").agg(\n","    (sum(col(\"quantity\")) / count(col(\"product_id\"))).alias(\"avg_quantity\")\n",")\n","\n","# Step 4: Compute Maximum Quantity for Each Order\n","order_max_df = orders_df.groupBy(\"order_id\").agg(\n","    max(col(\"quantity\")).alias(\"max_quantity\")\n",")\n","\n","# Step 5: Compute Global Average Quantity of All Orders\n","global_avg = order_avg_df.select(avg(\"avg_quantity\")).collect()[0][0]\n","\n","# Step 6: Filter Orders with Max Quantity Greater than Global Average\n","imbalanced_orders_df = order_max_df.filter(col(\"max_quantity\") > global_avg)\n","\n","# Step 7: Display the Result\n","imbalanced_orders_df.select(\"order_id\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"b13602fc-4f23-4104-9c25-7f8a6dc7d961","normalized_state":"finished","queued_time":"2025-03-25T17:26:49.9691766Z","session_start_time":null,"execution_start_time":"2025-03-25T17:26:49.9703579Z","execution_finish_time":"2025-03-25T17:26:51.5114953Z","parent_msg_id":"ac0bff2f-fed3-42fe-809b-8becb1c6a09f"},"text/plain":"StatementMeta(, b13602fc-4f23-4104-9c25-7f8a6dc7d961, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------+\n|order_id|\n+--------+\n|       1|\n|       3|\n+--------+\n\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fa79c557-f36b-491c-adcc-367dfca56d09"},{"cell_type":"markdown","source":["\n","---\n","\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Create Spark Session**\n","2. **Create DataFrame for `OrdersDetails` Table**\n","3. **Register it as a SQL View**\n","4. **Write and Execute SQL Query**\n","5. **Display the Output**\n"," \n","### **Code**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b106963b-c5cb-41bf-b09e-1f063ac238dd"},{"cell_type":"code","source":["# Step 1: Register DataFrame as a SQL View\n","orders_df.createOrReplaceTempView(\"OrdersDetails\")\n","\n","# Step 2: Run SQL Query\n","sql_query = \"\"\"\n","WITH OrderStats AS (\n","    SELECT order_id,\n","           MAX(quantity) AS max_quantity,\n","           SUM(quantity) * 1.0 / COUNT(product_id) AS avg_quantity\n","    FROM OrdersDetails\n","    GROUP BY order_id\n","),\n","GlobalAvg AS (\n","    SELECT AVG(avg_quantity) AS global_avg FROM OrderStats\n",")\n","SELECT o.order_id\n","FROM OrderStats o\n","JOIN GlobalAvg g\n","ON o.max_quantity > g.global_avg;\n","\"\"\"\n","\n","result_sql = spark.sql(sql_query)\n","\n","# Step 3: Display Output\n","result_sql.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"b13602fc-4f23-4104-9c25-7f8a6dc7d961","normalized_state":"finished","queued_time":"2025-03-25T17:26:50.0115199Z","session_start_time":null,"execution_start_time":"2025-03-25T17:26:51.5136629Z","execution_finish_time":"2025-03-25T17:26:52.9926602Z","parent_msg_id":"31b42c97-2016-4eaa-ab26-b92eef849cbe"},"text/plain":"StatementMeta(, b13602fc-4f23-4104-9c25-7f8a6dc7d961, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------+\n|order_id|\n+--------+\n|       1|\n|       3|\n+--------+\n\n"]}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"db3deb83-2a35-46b9-ad0e-739290db39dc"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","| Approach  | Method                      | Steps  |\n","|-----------|-----------------------------|--------|\n","| **Approach 1** | PySpark DataFrame API    | Uses `groupBy()`, `agg()`, and `filter()` |\n","| **Approach 2** | SQL Query in PySpark     | Uses `WITH`, `AVG()`, `MAX()`, `JOIN` |"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"be73c79f-fe05-4917-bf6a-10ea67b16bc1"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}