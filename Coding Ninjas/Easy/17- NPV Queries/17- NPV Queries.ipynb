{"cells":[{"cell_type":"markdown","source":["# **NPV Query**\n","\n","## **Problem Statement**\n","You are given two tables **NPV** and **Queries** with the following structure:\n","\n","### **Table: NPV**\n","| Column Name | Type |\n","|------------|------|\n","| `id`       | int  |\n","| `year`     | int  |\n","| `npv`      | int  |\n","\n","- **Primary Key:** (`id`, `year`)\n","- This table contains the net present value for each inventory.\n","\n","### **Table: Queries**\n","| Column Name | Type |\n","|------------|------|\n","| `id`       | int  |\n","| `year`     | int  |\n","\n","- **Primary Key:** (`id`, `year`)\n","- This table contains the queries for which we need to retrieve the NPV.\n","\n","### **Objective**\n","For each (`id`, `year`) in the **Queries** table:\n","- Retrieve the corresponding **npv** value from the **NPV** table.\n","- If no matching (`id`, `year`) exists in the **NPV** table, return `0` as the npv value.\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f1ee3ea6-4d61-4433-a370-7d6c48ccf9ee"},{"cell_type":"markdown","source":["\n","## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**\n","2. **Create DataFrames for `NPV` and `Queries` Tables**\n","3. **Perform Left Join on `id` and `year` Columns**\n","4. **Replace NULL npv Values with 0**\n","5. **Display the Result**\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"746457a9-fe81-4673-a75c-9dafa838afe8"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, coalesce, lit\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"NPVQueryMatching\").getOrCreate()\n","\n","# Step 2: Create DataFrames for NPV and Queries Tables\n","npv_data = [\n","    (1, 2018, 100), (7, 2020, 30), (13, 2019, 40), \n","    (1, 2019, 113), (2, 2008, 121), (3, 2009, 12), \n","    (11, 2020, 99), (7, 2019, 0)\n","]\n","npv_columns = [\"id\", \"year\", \"npv\"]\n","npv_df = spark.createDataFrame(npv_data, npv_columns)\n","\n","queries_data = [\n","    (1, 2019), (2, 2008), (3, 2009), (7, 2018), \n","    (7, 2019), (7, 2020), (13, 2019)\n","]\n","queries_columns = [\"id\", \"year\"]\n","queries_df = spark.createDataFrame(queries_data, queries_columns)\n","\n","# Step 3: Perform Left Join on 'id' and 'year'\n","result_df = queries_df.join(npv_df, on=[\"id\", \"year\"], how=\"left\")\n","\n","# Step 4: Replace NULL npv Values with 0\n","result_df = result_df.withColumn(\"npv\", coalesce(col(\"npv\"), lit(0)))\n","\n","# Step 5: Display the Result\n","result_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"a780d1ee-d731-4607-8e92-79522c7344ff","normalized_state":"finished","queued_time":"2025-03-24T17:56:53.0297677Z","session_start_time":null,"execution_start_time":"2025-03-24T17:56:53.0311087Z","execution_finish_time":"2025-03-24T17:56:54.5828996Z","parent_msg_id":"d81748b8-b11d-4f5c-9791-7fe2745b4687"},"text/plain":"StatementMeta(, a780d1ee-d731-4607-8e92-79522c7344ff, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+----+---+\n| id|year|npv|\n+---+----+---+\n|  1|2019|113|\n|  2|2008|121|\n|  3|2009| 12|\n|  7|2018|  0|\n|  7|2019|  0|\n|  7|2020| 30|\n| 13|2019| 40|\n+---+----+---+\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7082d14a-3e90-4bb4-87e3-084f93ddb004"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Create DataFrames for `NPV` and `Queries`**\n","2. **Register Both DataFrames as SQL Views**\n","3. **Write SQL Query Using `LEFT JOIN` and `COALESCE`**\n","4. **Execute SQL Query**\n","5. **Display Output**\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b35acc4a-b608-4ded-aef3-9eacaa2307a1"},{"cell_type":"code","source":["# Step 1: Register DataFrames as SQL Views\n","npv_df.createOrReplaceTempView(\"NPV\")\n","queries_df.createOrReplaceTempView(\"Queries\")\n","\n","# Step 2: Run SQL Query\n","sql_query = \"\"\"\n","SELECT q.id, q.year, COALESCE(n.npv, 0) AS npv\n","FROM Queries q\n","LEFT JOIN NPV n\n","ON q.id = n.id AND q.year = n.year;\n","\"\"\"\n","\n","result_sql = spark.sql(sql_query)\n","\n","# Step 3: Display Output\n","result_sql.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"a780d1ee-d731-4607-8e92-79522c7344ff","normalized_state":"finished","queued_time":"2025-03-24T17:56:53.0781003Z","session_start_time":null,"execution_start_time":"2025-03-24T17:56:54.585873Z","execution_finish_time":"2025-03-24T17:56:56.1052899Z","parent_msg_id":"f25ef92c-068b-438d-a596-ff08468cd59d"},"text/plain":"StatementMeta(, a780d1ee-d731-4607-8e92-79522c7344ff, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+----+---+\n| id|year|npv|\n+---+----+---+\n|  1|2019|113|\n|  2|2008|121|\n|  3|2009| 12|\n|  7|2018|  0|\n|  7|2019|  0|\n|  7|2020| 30|\n| 13|2019| 40|\n+---+----+---+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c56bf398-371b-4c0f-b563-ee6209017bed"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","| Approach  | Method                      | Steps  |\n","|-----------|-----------------------------|--------|\n","| **Approach 1** | PySpark DataFrame API    | Uses `join()` and `coalesce()` |\n","| **Approach 2** | SQL Query in PySpark     | Uses `LEFT JOIN` and `COALESCE()` |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"909afd3e-0519-43d3-a4dc-405f3ed7ed2f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}