{"cells":[{"cell_type":"markdown","source":["# **Marvel Cities**\n","\n","## **Problem Statement**\n","You are given a table **CITY** with the following structure:\n","\n","### **Table: CITY**\n","| Column Name  | Type    |\n","|-------------|--------|\n","| `ID`         | Number  |\n","| `Name`       | Varchar |\n","| `CountryCode`| Varchar |\n","| `Population` | Number  |\n","\n","### **Objective**\n","Write a query to return **all columns** for **cities in Marvel (CountryCode = 'Marv')** where **the population is greater than 100,000**.\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"cbf057b1-640d-4234-9389-1f78627605c4"},{"cell_type":"markdown","source":["## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**\n","2. **Create a DataFrame for `CITY` Table**\n","3. **Filter rows where `CountryCode = 'Marv'` and `Population > 100000`**\n","4. **Select all columns and display the results**\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4c13ae36-9858-4f59-a81c-98ec5b7e9e63"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"MarvelCities\").getOrCreate()\n","\n","# Step 2: Create DataFrame for CITY Table\n","city_data = [\n","    (1, \"New York\", \"USA\", 8500000),\n","    (2, \"Los Angeles\", \"USA\", 4000000),\n","    (3, \"Marvel City\", \"Marv\", 120000),\n","    (4, \"Small Town\", \"Marv\", 50000),\n","    (5, \"Mega Marvel\", \"Marv\", 200000),\n","    (6, \"Gotham\", \"DC\", 1500000)\n","]\n","city_columns = [\"ID\", \"Name\", \"CountryCode\", \"Population\"]\n","\n","city_df = spark.createDataFrame(city_data, city_columns)\n","\n","# Step 3: Filter Marvel cities with population > 100000\n","filtered_df = city_df.filter((col(\"CountryCode\") == \"Marv\") & (col(\"Population\") > 100000))\n","\n","# Step 4: Display Output\n","filtered_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"2c10692f-7565-4191-89c0-1265c01dbf89","normalized_state":"finished","queued_time":"2025-03-19T16:23:59.9417916Z","session_start_time":"2025-03-19T16:23:59.9431624Z","execution_start_time":"2025-03-19T16:24:15.8580839Z","execution_finish_time":"2025-03-19T16:24:22.2377382Z","parent_msg_id":"edf84554-b9a4-4628-b609-aa29803df1a5"},"text/plain":"StatementMeta(, 2c10692f-7565-4191-89c0-1265c01dbf89, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+-----------+-----------+----------+\n| ID|       Name|CountryCode|Population|\n+---+-----------+-----------+----------+\n|  3|Marvel City|       Marv|    120000|\n|  5|Mega Marvel|       Marv|    200000|\n+---+-----------+-----------+----------+\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f64a71fa-6aad-4b4d-bbd2-d1b647ea0627"},{"cell_type":"markdown","source":["---\n","\n","# **Code**\n","\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Create Spark Session**\n","2. **Create DataFrame for `CITY` Table**\n","3. **Register it as a SQL View**\n","4. **Write and Execute SQL Query**\n","5. **Display the Output**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"54a1d97c-919f-41ce-af0c-8148c7ecda47"},{"cell_type":"code","source":["# Step 1: Register DataFrame as a SQL View\n","city_df.createOrReplaceTempView(\"CITY\")\n","\n","# Step 2: Run SQL Query\n","sql_query = \"\"\"\n","SELECT * \n","FROM CITY\n","WHERE CountryCode = 'Marv' AND Population > 100000;\n","\"\"\"\n","\n","result_sql = spark.sql(sql_query)\n","\n","# Step 3: Display Output\n","result_sql.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"2c10692f-7565-4191-89c0-1265c01dbf89","normalized_state":"finished","queued_time":"2025-03-19T16:24:00.1439827Z","session_start_time":null,"execution_start_time":"2025-03-19T16:24:22.2402684Z","execution_finish_time":"2025-03-19T16:24:23.6499246Z","parent_msg_id":"6a84f70a-0451-45e3-9823-b772636c127c"},"text/plain":"StatementMeta(, 2c10692f-7565-4191-89c0-1265c01dbf89, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+-----------+-----------+----------+\n| ID|       Name|CountryCode|Population|\n+---+-----------+-----------+----------+\n|  3|Marvel City|       Marv|    120000|\n|  5|Mega Marvel|       Marv|    200000|\n+---+-----------+-----------+----------+\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a29d13a6-2162-4486-8efb-05c2eb17fc9d"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","| Approach  | Method                      | Steps  |\n","|-----------|-----------------------------|--------|\n","| **Approach 1** | PySpark DataFrame API    | Uses `filter()` and `col()` to apply conditions |\n","| **Approach 2** | SQL Query in PySpark     | Uses SQL `WHERE` clause in PySpark |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b19b29e9-9ada-47fc-b11c-139261a779a5"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}