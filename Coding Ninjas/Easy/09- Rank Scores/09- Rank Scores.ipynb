{"cells":[{"cell_type":"markdown","source":["# **Rank Scores**\n","\n","## **Problem Statement**\n","Given a `Scores` table:\n","\n","### **Table: Scores**\n","| Column Name | Type  |\n","|-------------|------|\n","| `Id`        | int  |\n","| `Score`     | float |\n","\n","- The table contains **student scores**.\n","- The ranking should:\n","  - **Be ordered by highest score.**\n","  - **Handle ties correctly (same rank for duplicate values).**\n","  - **Ensure no gaps in ranking numbers (next rank should be consecutive).**\n","\n","---\n","\n","## **Example**\n","\n","### **Input:**\n","| Id | Score |\n","|----|-------|\n","| 1  | 3.50  |\n","| 2  | 3.65  |\n","| 3  | 4.00  |\n","| 4  | 3.85  |\n","| 5  | 4.00  |\n","| 6  | 3.65  |\n","\n","### **Expected Output:**\n","| Score | Rank |\n","|-------|------|\n","| 4.00  | 1    |\n","| 4.00  | 1    |\n","| 3.85  | 2    |\n","| 3.65  | 3    |\n","| 3.65  | 3    |\n","| 3.50  | 4    |\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1859b5ce-4eab-494c-833c-aa3189543f52"},{"cell_type":"markdown","source":["## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**  \n","   - Create a Spark session.\n","2. **Load Data**  \n","   - Read `Scores.csv` into a PySpark DataFrame.\n","3. **Apply Ranking**  \n","   - Use `dense_rank()` to **assign ranks without gaps**.\n","   - Use `desc(\"Score\")` to rank **higher scores first**.\n","4. **Display the Output**  \n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e8d8bd3d-986f-4a49-9b21-623745f5304f"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","from pyspark.sql.window import Window\n","from pyspark.sql.functions import dense_rank\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"RankScores\").getOrCreate()\n","\n","# Step 2: Load Data into DataFrame\n","data = [(1, 3.50), (2, 3.65), (3, 4.00), (4, 3.85), (5, 4.00), (6, 3.65)]\n","columns = [\"Id\", \"Score\"]\n","scores_df = spark.createDataFrame(data, columns)\n","\n","# Step 3: Define Window Specification\n","window_spec = Window.orderBy(col(\"Score\").desc())\n","\n","# Step 4: Compute Dense Rank\n","ranked_df = scores_df.withColumn(\"Rank\", dense_rank().over(window_spec))\n","\n","# Step 5: Display the Output\n","ranked_df.select(\"Score\", \"Rank\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"593ba31e-032e-43ae-8243-362894846f14","normalized_state":"finished","queued_time":"2025-03-17T17:44:30.7850988Z","session_start_time":null,"execution_start_time":"2025-03-17T17:44:30.7867187Z","execution_finish_time":"2025-03-17T17:44:57.5050456Z","parent_msg_id":"7a072123-017c-458c-9407-417408a57251"},"text/plain":"StatementMeta(, 593ba31e-032e-43ae-8243-362894846f14, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+----+\n|Score|Rank|\n+-----+----+\n|  4.0|   1|\n|  4.0|   1|\n| 3.85|   2|\n| 3.65|   3|\n| 3.65|   3|\n|  3.5|   4|\n+-----+----+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe5919eb-4ce7-47df-864e-d3fcf2a04863"},{"cell_type":"markdown","source":["## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Create Temporary SQL Views**  \n","   - Register `Scores` as a **temporary table**.\n","2. **Write and Execute SQL Query**  \n","   - Use `DENSE_RANK()` **to avoid gaps**.\n","   - Use `ORDER BY Score DESC` **to rank higher scores first**.\n","3. **Show Results**  \n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2b423682-5f30-4e6f-aea1-0a0773180884"},{"cell_type":"code","source":["# Step 1: Create Temporary SQL View\n","scores_df.createOrReplaceTempView(\"Scores\")\n","\n","# Step 2: Run SQL Query\n","query = \"\"\"\n","SELECT Score, DENSE_RANK() OVER (ORDER BY Score DESC) AS Rank\n","FROM Scores\n","\"\"\"\n","\n","# Step 3: Execute SQL Query\n","sql_result = spark.sql(query)\n","\n","# Step 4: Show Output\n","sql_result.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"593ba31e-032e-43ae-8243-362894846f14","normalized_state":"finished","queued_time":"2025-03-17T17:44:31.0014545Z","session_start_time":null,"execution_start_time":"2025-03-17T17:44:57.5081209Z","execution_finish_time":"2025-03-17T17:44:58.4203484Z","parent_msg_id":"204a3d7f-3bc7-4c39-a639-def0f59edddd"},"text/plain":"StatementMeta(, 593ba31e-032e-43ae-8243-362894846f14, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+----+\n|Score|Rank|\n+-----+----+\n|  4.0|   1|\n|  4.0|   1|\n| 3.85|   2|\n| 3.65|   3|\n| 3.65|   3|\n|  3.5|   4|\n+-----+----+\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8141a5eb-bf0b-415a-b834-186830316603"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","| Approach | Method | Steps |\n","|----------|--------|-------|\n","| **Approach 1** | PySpark DataFrame API | Uses `dense_rank()` function with `Window` |\n","| **Approach 2** | SQL Query in PySpark | Uses `DENSE_RANK()` in SQL |"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"142d13e9-5ec0-490d-80c5-e5d700331f53"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}