{"cells":[{"cell_type":"markdown","source":["# **Sales Executive**\n","\n","### **Problem Statement**\n","Given three tables: **Salesperson**, **Company**, and **Orders**, output the names of all salespeople who **did not** sell to the company 'RED'.\n","\n","### **Example Data**\n","\n","#### **Table: Salesperson**\n","| sales_id | name  | salary  | commission_rate | hire_date  |\n","|----------|-------|---------|-----------------|------------|\n","| 1        | John  | 100000  | 6               | 4/1/2006   |\n","| 2        | Amy   | 120000  | 5               | 5/1/2010   |\n","| 3        | Mark  | 65000   | 12              | 12/25/2008 |\n","| 4        | Pam   | 25000   | 25              | 1/1/2005   |\n","| 5        | Alex  | 50000   | 10              | 2/3/2007   |\n","\n","#### **Table: Company**\n","| com_id | name   | city      |\n","|--------|--------|-----------|\n","| 1      | RED    | Boston    |\n","| 2      | ORANGE | New York  |\n","| 3      | YELLOW | Boston    |\n","| 4      | GREEN  | Austin    |\n","\n","#### **Table: Orders**\n","| order_id | order_date | com_id | sales_id | amount  |\n","|----------|------------|--------|----------|---------|\n","| 1        | 1/1/2014   | 3      | 4        | 100000  |\n","| 2        | 2/1/2014   | 4      | 5        | 5000    |\n","| 3        | 3/1/2014   | 1      | 1        | 50000   |\n","| 4        | 4/1/2014   | 1      | 4        | 25000   |\n","\n","### **Expected Output**\n","| name  |\n","|-------|\n","| Amy   |\n","| Mark  |\n","| Alex  |\n","\n","---\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0a91a7c5-788d-4a8b-aa46-b4fa841f5368"},{"cell_type":"markdown","source":["## **üî• Approach 1: Using PySpark DataFrame API**\n","### **Steps:**\n","1. **Initialize Spark Session**  \n","   - Create a Spark session to work with DataFrames.\n","   \n","2. **Load Data into DataFrames**  \n","   - Read the `Salesperson`, `Company`, and `Orders` CSV files (assuming they are stored locally).  \n","   \n","3. **Join `Orders` with `Company`**  \n","   - Filter only orders related to the company `'RED'`.  \n","   - Select the unique `sales_id` who sold to `'RED'`.  \n","\n","4. **Filter Salespersons Who Didn't Sell to `'RED'`**  \n","   - Use **anti-join** to exclude salespeople who are in the previous filtered list.  \n","\n","5. **Display the result**  \n","   - Select only the `name` column and display the output.  \n","\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"baf93ae6-a3e7-49d2-9bb9-b10fe649bf86"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Initialize Spark Session\n","spark = SparkSession.builder.appName(\"SalesExecutive\").getOrCreate()\n","\n","# Create DataFrames for Salesperson, Company, and Orders\n","salesperson_data = [(1, \"John\", 100000, 6, \"4/1/2006\"),\n","                    (2, \"Amy\", 120000, 5, \"5/1/2010\"),\n","                    (3, \"Mark\", 65000, 12, \"12/25/2008\"),\n","                    (4, \"Pam\", 25000, 25, \"1/1/2005\"),\n","                    (5, \"Alex\", 50000, 10, \"2/3/2007\")]\n","\n","salesperson_df = spark.createDataFrame(salesperson_data, [\"sales_id\", \"name\", \"salary\", \"commission_rate\", \"hire_date\"])\n","\n","company_data = [(1, \"RED\", \"Boston\"),\n","                (2, \"ORANGE\", \"New York\"),\n","                (3, \"YELLOW\", \"Boston\"),\n","                (4, \"GREEN\", \"Austin\")]\n","\n","company_df = spark.createDataFrame(company_data, [\"com_id\", \"name\", \"city\"])\n","\n","orders_data = [(1, \"1/1/2014\", 3, 4, 100000),\n","               (2, \"2/1/2014\", 4, 5, 5000),\n","               (3, \"3/1/2014\", 1, 1, 50000),\n","               (4, \"4/1/2014\", 1, 4, 25000)]\n","\n","orders_df = spark.createDataFrame(orders_data, [\"order_id\", \"order_date\", \"com_id\", \"sales_id\", \"amount\"])\n","\n","# Find salespeople who sold to 'RED'\n","red_sales_df = orders_df.join(company_df, \"com_id\").filter(col(\"name\") == \"RED\").select(\"sales_id\")\n","\n","# Find salespeople who didn't sell to 'RED'\n","result_df = salesperson_df.join(red_sales_df, \"sales_id\", \"left_anti\").select(\"name\")\n","\n","# Display result\n","result_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"987f7e07-9883-4a61-94f5-5dbe0c9b867d","normalized_state":"finished","queued_time":"2025-03-13T17:25:51.7840575Z","session_start_time":"2025-03-13T17:25:51.785491Z","execution_start_time":"2025-03-13T17:26:07.2907014Z","execution_finish_time":"2025-03-13T17:26:12.5763254Z","parent_msg_id":"e3a01b8c-11bf-4686-9564-cd9cbe1dbcf1"},"text/plain":"StatementMeta(, 987f7e07-9883-4a61-94f5-5dbe0c9b867d, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----+\n|name|\n+----+\n| Amy|\n|Mark|\n|Alex|\n+----+\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5a4403f6-143e-4a28-b848-92e276dbdb6d"},{"cell_type":"markdown","source":["\n","\n","## **üî• Approach 2: Using SQL Query in PySpark**\n","### **Steps:**\n","1. **Initialize Spark Session**\n","2. **Load Data into DataFrames**\n","3. **Create Temporary Views**  \n","   - Convert PySpark DataFrames into SQL temp tables.  \n","   \n","4. **Write SQL Query to Solve the Problem**  \n","   - Find all salespeople who **did** make sales to `'RED'`.  \n","   - Use **NOT IN** to exclude them.  \n","\n","5. **Execute Query and Display Results**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"77881687-6052-48df-8560-66b8410c94e5"},{"cell_type":"code","source":["# Step 1: Create Temporary Views\n","salesperson_df.createOrReplaceTempView(\"Salesperson\")\n","company_df.createOrReplaceTempView(\"Company\")\n","orders_df.createOrReplaceTempView(\"Orders\")\n","\n","# Step 2: Execute SQL Query\n","query = \"\"\"\n","SELECT s.name\n","FROM Salesperson s\n","WHERE s.sales_id NOT IN (\n","    SELECT DISTINCT o.sales_id\n","    FROM Orders o\n","    JOIN Company c ON o.com_id = c.com_id\n","    WHERE c.name = 'RED'\n",")\n","\"\"\"\n","\n","result_sql = spark.sql(query)\n","\n","# Step 3: Display result\n","result_sql.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"987f7e07-9883-4a61-94f5-5dbe0c9b867d","normalized_state":"finished","queued_time":"2025-03-13T17:25:51.7848892Z","session_start_time":null,"execution_start_time":"2025-03-13T17:26:12.5787854Z","execution_finish_time":"2025-03-13T17:26:16.0059642Z","parent_msg_id":"e3ede7b3-356a-4660-9f44-420442fbcc65"},"text/plain":"StatementMeta(, 987f7e07-9883-4a61-94f5-5dbe0c9b867d, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----+\n|name|\n+----+\n| Amy|\n|Mark|\n|Alex|\n+----+\n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7b7b7cdb-bfcf-451d-bff8-10e277d67554"},{"cell_type":"markdown","source":["\n","## **üìù Summary Table: Approach 1 vs Approach 2**\n","| Approach | Method | Description |\n","|----------|--------|-------------|\n","| **Approach 1** | **DataFrame API** | Uses PySpark functions like `.join()`, `.filter()`, and `.left_anti` to find salespeople who never sold to `'RED'`. |\n","| **Approach 2** | **SQL in PySpark** | Uses SQL `NOT IN` and `JOIN` to filter salespeople who never sold to `'RED'`. |\n","\n","Both approaches yield the same result. üöÄ"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cd4dce9a-293f-4c59-aaeb-a93a21cead4d"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}