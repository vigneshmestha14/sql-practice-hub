{"cells":[{"cell_type":"markdown","source":["# **Employees Earning More Than Their Managers**\n","\n","## **Problem Statement**\n","Given a table `Employee` containing employee information including their `Id`, `Name`, `Salary`, and `ManagerId`, write a query to find employees who earn **more than their managers**.\n","\n","---\n","\n","## **Table: Employee**\n","\n","| Column Name | Type    |\n","|-------------|---------|\n","| Id          | int     |\n","| Name        | varchar |\n","| Salary      | int     |\n","| ManagerId   | int     |\n","\n","- `Id` is the primary key.\n","- `ManagerId` is a foreign key that refers to `Id`.\n","\n","---\n","\n","### **Example**\n","\n","#### **Input Table**\n","| Id | Name  | Salary | ManagerId |\n","|----|-------|--------|-----------|\n","| 1  | Joe   | 70000  | 3         |\n","| 2  | Henry | 80000  | 4         |\n","| 3  | Sam   | 60000  | NULL      |\n","| 4  | Max   | 90000  | NULL      |\n","\n","#### **Expected Output**\n","| Employee |\n","|----------|\n","| Joe      |\n","\n","Joe earns 70,000 while his manager Sam earns 60,000 â€” so only Joe qualifies.\n","\n","---\n","\n","## **Approach 1: PySpark DataFrame API**\n","\n","### **Steps**\n","1. Create the Employee DataFrame.\n","2. Perform a self-join to compare each employee with their manager.\n","3. Filter employees whose salary is greater than their manager's.\n","4. Select the employee's name.\n","\n","### **Code**\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a0b04c46-e95c-4cfd-82d4-66c59c3528fd"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"Employee\").getOrCreate()\n","\n","# Step 2: Create Employee DataFrame\n","data = [\n","    (1, \"Joe\", 70000, 3),\n","    (2, \"Henry\", 80000, 4),\n","    (3, \"Sam\", 60000, None),\n","    (4, \"Max\", 90000, None)\n","]\n","columns = [\"Id\", \"Name\", \"Salary\", \"ManagerId\"]\n","df = spark.createDataFrame(data, columns)\n","\n","# Step 3: Self-join on Employee and Manager\n","joined = df.alias(\"e\").join(\n","    df.alias(\"m\"),\n","    col(\"e.ManagerId\") == col(\"m.Id\")\n",")\n","\n","# Step 4: Filter where employee's salary > manager's salary\n","result = joined.filter(col(\"e.Salary\") > col(\"m.Salary\"))\n","\n","# Step 5: Select employee names\n","result.select(col(\"e.Name\").alias(\"Employee\")).show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"c7c94a52-d67c-4a12-802d-0af1caa93a41","normalized_state":"finished","queued_time":"2025-04-07T16:39:35.3155452Z","session_start_time":null,"execution_start_time":"2025-04-07T16:39:35.3167286Z","execution_finish_time":"2025-04-07T16:39:36.8023661Z","parent_msg_id":"74494edd-38d1-45a3-ab12-7fde555ae46e"},"text/plain":"StatementMeta(, c7c94a52-d67c-4a12-802d-0af1caa93a41, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------+\n|Employee|\n+--------+\n|     Joe|\n+--------+\n\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ea9e92b5-5a49-4765-a753-92371930e4a9"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","\n","### **Steps**\n","1. Register the DataFrame as a temp SQL view.\n","2. Use a self-join to compare employee and manager salaries.\n","3. Filter and return employees who earn more than their manager.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5b13719e-16f7-4efb-ac54-f4005c266081"},{"cell_type":"code","source":["df.createOrReplaceTempView(\"Employee\")\n","\n","sql_result = spark.sql(\"\"\"\n","    SELECT e.Name AS Employee\n","    FROM Employee e\n","    JOIN Employee m ON e.ManagerId = m.Id\n","    WHERE e.Salary > m.Salary\n","\"\"\")\n","\n","sql_result.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"submitted","livy_statement_state":"running","session_id":"c7c94a52-d67c-4a12-802d-0af1caa93a41","normalized_state":"running","queued_time":"2025-04-07T16:39:35.3597673Z","session_start_time":null,"execution_start_time":"2025-04-07T16:39:36.8044197Z","execution_finish_time":null,"parent_msg_id":"17c68428-6564-46be-b6a7-538dfa77def2"},"text/plain":"StatementMeta(, c7c94a52-d67c-4a12-802d-0af1caa93a41, 8, Submitted, Running, Running)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ddec3d2d-0adf-4ae4-8274-ac2c5cb1ebee"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","\n","| Approach         | Method                | Key Technique         |\n","|------------------|------------------------|------------------------|\n","| **Approach 1**   | PySpark DataFrame API  | `self-join`, `filter` |\n","| **Approach 2**   | SQL in PySpark         | `JOIN`, `WHERE`       |"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"49e101bb-60db-49b6-8bd8-46bc6f7aa16e"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}