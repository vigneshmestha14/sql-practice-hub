{"cells":[{"cell_type":"markdown","source":["# **Employee Bonus**\n","\n","## **Problem Statement**\n","\n","You are given two tables: `Employee` and `Bonus`. Write a SQL query to **select all employeesâ€™ names and their bonuses**, but **only display those whose bonus is less than 1000** or whose bonus **does not exist** (i.e., NULL).\n","\n","---\n","\n","### **Table: Employee**\n","\n","| empId | name   | supervisor | salary |\n","|-------|--------|------------|--------|\n","| 1     | John   | 3          | 1000   |\n","| 2     | Dan    | 3          | 2000   |\n","| 3     | Brad   | NULL       | 4000   |\n","| 4     | Thomas | 3          | 4000   |\n","\n","---\n","\n","### **Table: Bonus**\n","\n","| empId | bonus |\n","|-------|-------|\n","| 2     | 500   |\n","| 4     | 2000  |\n","\n","---\n","\n","### **Expected Output**\n","\n","| name  | bonus |\n","|-------|-------|\n","| Dan   | 500   |\n","| John  | NULL  |\n","| Brad  | NULL  |\n","\n","---\n","\n","## **Approach 1: PySpark DataFrame API**\n","\n","### **Steps**\n","1. Load both Employee and Bonus data into DataFrames.\n","2. Perform a **left join** on `empId` to include all employees.\n","3. Filter:\n","   - `bonus < 1000`\n","   - OR `bonus IS NULL`\n","4. Select `name` and `bonus`.\n","\n","### **Code**\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"575e9c1b-74a1-440f-a6c4-d9ea9598925c"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, lit\n","\n","# Step 1: Create Spark session\n","spark = SparkSession.builder.appName(\"EmployeeBonus\").getOrCreate()\n","\n","# Step 2: Sample data\n","employee_data = [(1, 'John', 3, 1000),\n","                 (2, 'Dan', 3, 2000),\n","                 (3, 'Brad', None, 4000),\n","                 (4, 'Thomas', 3, 4000)]\n","employee_columns = [\"empId\", \"name\", \"supervisor\", \"salary\"]\n","employee_df = spark.createDataFrame(employee_data, employee_columns)\n","\n","bonus_data = [(2, 500), (4, 2000)]\n","bonus_columns = [\"empId\", \"bonus\"]\n","bonus_df = spark.createDataFrame(bonus_data, bonus_columns)\n","\n","# Step 3: Left join\n","joined_df = employee_df.join(bonus_df, on=\"empId\", how=\"left\")\n","\n","# Step 4: Filter based on bonus < 1000 or bonus is null\n","filtered_df = joined_df.filter((col(\"bonus\") < 1000) | col(\"bonus\").isNull())\n","\n","# Step 5: Select name and bonus\n","result_df = filtered_df.select(\"name\", \"bonus\")\n","\n","result_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"0ba253e9-e372-41b6-9689-72c9a9218d7d","normalized_state":"finished","queued_time":"2025-04-10T17:35:40.0360536Z","session_start_time":null,"execution_start_time":"2025-04-10T17:35:40.0372505Z","execution_finish_time":"2025-04-10T17:35:41.527Z","parent_msg_id":"fb74f825-80df-4c7d-9ae9-c60b53247f85"},"text/plain":"StatementMeta(, 0ba253e9-e372-41b6-9689-72c9a9218d7d, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----+-----+\n|name|bonus|\n+----+-----+\n|John| null|\n| Dan|  500|\n|Brad| null|\n+----+-----+\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"64370b36-4247-4f87-af7d-643630e083fa"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","\n","### **Steps**\n","1. Perform a **LEFT JOIN** between `Employee` and `Bonus` on `empId`.\n","2. Use **WHERE** clause to filter for:\n","   - `bonus < 1000`\n","   - OR `bonus IS NULL`.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d5a04920-1371-4ebb-b826-c11b9f8a832d"},{"cell_type":"code","source":["employee_df.createOrReplaceTempView(\"Employee\")\n","bonus_df.createOrReplaceTempView(\"Bonus\")\n","\n","spark.sql(\"\"\"\n","    SELECT e.name, b.bonus\n","    FROM Employee e\n","    LEFT JOIN Bonus b ON e.empId = b.empId\n","    WHERE b.bonus < 1000 OR b.bonus IS NULL\n","\"\"\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"0ba253e9-e372-41b6-9689-72c9a9218d7d","normalized_state":"finished","queued_time":"2025-04-10T17:35:40.0886046Z","session_start_time":null,"execution_start_time":"2025-04-10T17:35:41.5290482Z","execution_finish_time":"2025-04-10T17:35:43.0877383Z","parent_msg_id":"f4bffaac-cd6d-492d-8f27-8c6e15f026a4"},"text/plain":"StatementMeta(, 0ba253e9-e372-41b6-9689-72c9a9218d7d, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----+-----+\n|name|bonus|\n+----+-----+\n|John| null|\n| Dan|  500|\n|Brad| null|\n+----+-----+\n\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"631b4423-dec6-414f-a41e-3f33dcaf5a35"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","\n","| Approach         | Method               | Key Techniques                     |\n","|------------------|----------------------|-------------------------------------|\n","| **Approach 1**   | PySpark DataFrame API| `left join + filter by bonus`       |\n","| **Approach 2**   | SQL in PySpark       | `LEFT JOIN + WHERE (bonus check)`   |"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d3f3ab0a-5384-4495-87c6-e0b8a16de105"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}