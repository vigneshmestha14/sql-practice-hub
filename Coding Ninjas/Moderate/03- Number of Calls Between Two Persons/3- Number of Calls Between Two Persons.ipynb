{"cells":[{"cell_type":"markdown","source":["# **Number of Calls Between Two Persons**\n","\n","## **Problem Statement**\n","You are given a table **Calls** with the following structure:\n","\n","### **Table: Calls**\n","| Column Name | Type |\n","|-------------|------|\n","| `from_id`   | int  |\n","| `to_id`     | int  |\n","| `duration`  | int  |\n","\n","- This table does **not have a primary key** and **may contain duplicates**.\n","- It contains the duration of a phone call between `from_id` and `to_id`.\n","- `from_id` is **not equal** to `to_id`.\n","\n","### **Objective**\n","Write a query to **report the number of calls** and **the total call duration** between each **pair of distinct persons** `(person1, person2)` where `person1 < person2`.\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"348a29fc-cfc7-4d63-bad5-7e5124644699"},{"cell_type":"markdown","source":["## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**\n","2. **Create a DataFrame for `Calls` Table**\n","3. **Normalize the Data** (Ensure `person1 < person2`)\n","4. **Group by (person1, person2) and Aggregate**\n","5. **Select and Display the Result**\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fb391c70-595b-4814-82cb-37908586f9c9"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, sum, count, least, greatest\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"NumberOfCalls\").getOrCreate()\n","\n","# Step 2: Create DataFrame for Calls Table\n","calls_data = [\n","    (1, 2, 59),\n","    (2, 1, 11),\n","    (1, 3, 20),\n","    (3, 4, 100),\n","    (3, 4, 200),\n","    (3, 4, 200),\n","    (4, 3, 499),\n","]\n","calls_columns = [\"from_id\", \"to_id\", \"duration\"]\n","\n","calls_df = spark.createDataFrame(calls_data, calls_columns)\n","\n","# Step 3: Normalize Data (Ensure person1 < person2)\n","normalized_df = calls_df.withColumn(\"person1\", least(col(\"from_id\"), col(\"to_id\"))) \\\n","                        .withColumn(\"person2\", greatest(col(\"from_id\"), col(\"to_id\")))\n","\n","# Step 4: Group by (person1, person2) and Aggregate\n","result_df = normalized_df.groupBy(\"person1\", \"person2\") \\\n","                         .agg(count(\"*\").alias(\"call_count\"), sum(\"duration\").alias(\"total_duration\"))\n","\n","# Step 5: Display Result\n","result_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"6c26ad54-4998-4260-9902-28cdbc86f37d","normalized_state":"finished","queued_time":"2025-03-29T16:55:35.7039129Z","session_start_time":null,"execution_start_time":"2025-03-29T16:55:35.7052276Z","execution_finish_time":"2025-03-29T16:55:36.5912243Z","parent_msg_id":"6ff5ae50-f460-4cfd-a124-8294d2006389"},"text/plain":"StatementMeta(, 6c26ad54-4998-4260-9902-28cdbc86f37d, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-------+-------+----------+--------------+\n|person1|person2|call_count|total_duration|\n+-------+-------+----------+--------------+\n|      1|      2|         2|            70|\n|      1|      3|         1|            20|\n|      3|      4|         4|           999|\n+-------+-------+----------+--------------+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7ffcac63-ca37-499e-aa9b-78b35560b565"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Create Spark Session**\n","2. **Create DataFrame for `Calls` Table**\n","3. **Register it as a SQL View**\n","4. **Write and Execute SQL Query**\n","5. **Display the Output**\n","\n","\n","### **Code**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"802a080d-4121-43bb-acdd-1e0888ff23b8"},{"cell_type":"code","source":["# Step 1: Register DataFrame as a SQL View\n","calls_df.createOrReplaceTempView(\"Calls\")\n","\n","# Step 2: Run SQL Query\n","sql_query = \"\"\"\n","SELECT \n","    LEAST(from_id, to_id) AS person1, \n","    GREATEST(from_id, to_id) AS person2, \n","    COUNT(*) AS call_count, \n","    SUM(duration) AS total_duration\n","FROM Calls\n","GROUP BY person1, person2;\n","\"\"\"\n","\n","result_sql = spark.sql(sql_query)\n","\n","# Step 3: Display Output\n","result_sql.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"6c26ad54-4998-4260-9902-28cdbc86f37d","normalized_state":"finished","queued_time":"2025-03-29T16:55:35.799648Z","session_start_time":null,"execution_start_time":"2025-03-29T16:55:36.5932721Z","execution_finish_time":"2025-03-29T16:55:37.4456958Z","parent_msg_id":"16bcd650-4e12-4d45-b9ee-5e36d873310d"},"text/plain":"StatementMeta(, 6c26ad54-4998-4260-9902-28cdbc86f37d, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-------+-------+----------+--------------+\n|person1|person2|call_count|total_duration|\n+-------+-------+----------+--------------+\n|      1|      2|         2|            70|\n|      1|      3|         1|            20|\n|      3|      4|         4|           999|\n+-------+-------+----------+--------------+\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fb94e4d3-6303-4c99-8eb2-42f18b441339"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","| Approach  | Method                      | Steps  |\n","|-----------|-----------------------------|--------|\n","| **Approach 1** | PySpark DataFrame API    | Uses `.withColumn()`, `.groupBy()`, `.agg()` |\n","| **Approach 2** | SQL Query in PySpark     | Uses `LEAST()`, `GREATEST()`, `GROUP BY`, `SUM()` |\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"dce2f359-675d-4b99-a5b3-6db7e904d6fe"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}