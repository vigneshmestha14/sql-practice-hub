{"cells":[{"cell_type":"markdown","source":["# **Patients With a Condition**\n","\n","## **Problem Statement**\n","We have a table named **Patients**.\n","\n","### **Table: Patients**\n","This table contains hospital patient information.\n","\n","| Column Name  | Type    |\n","|-------------|---------|\n","| patient_id  | int     |\n","| patient_name | varchar |\n","| conditions  | varchar |\n","\n","- `patient_id` is the **primary key**.\n","- `conditions` contains **0 or more medical codes separated by spaces**.\n","- **Type I Diabetes** always starts with the **prefix \"DIAB1\"**.\n","\n","---\n","\n","## **Objective**\n","Find the `patient_id`, `patient_name`, and `conditions` for patients who have **Type I Diabetes** (i.e., their `conditions` column contains a code that starts with `\"DIAB1\"`).\n","\n","### **Example**\n","#### **Input: Patients Table**\n","| patient_id | patient_name | conditions   |\n","|------------|--------------|--------------|\n","| 1          | Daniel       | YFEV COUGH   |\n","| 2          | Alice        |              |\n","| 3          | Bob          | DIAB100 MYOP |\n","| 4          | George       | ACNE DIAB100 |\n","| 5          | Alain        | DIAB201      |\n","\n","#### **Expected Output**\n","| patient_id | patient_name | conditions   |\n","|------------|--------------|--------------|\n","| 3          | Bob          | DIAB100 MYOP |\n","| 4          | George       | ACNE DIAB100 |\n","\n","- **Bob** has `DIAB100`, which starts with `\"DIAB1\"`, so he is included.\n","- **George** has `DIAB100`, which starts with `\"DIAB1\"`, so he is included.\n","- **Daniel, Alice, and Alain** do not meet the condition, so they are excluded.\n","\n","---\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"fac11456-3d65-47d1-8041-059865511d66"},{"cell_type":"markdown","source":["## **Approach 1: PySpark DataFrame API**\n","### **Steps**\n","1. **Initialize Spark Session**\n","2. **Create DataFrame for Patients**\n","3. **Filter Rows Where `conditions` Contains `\"DIAB1\"` Using `rlike()`**\n","4. **Select Required Columns**\n","5. **Display the Result**\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4144d1e-1d25-471c-a467-e68163e085c8"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Step 1: Initialize Spark Session\n","spark = SparkSession.builder.appName(\"PatientsWithCondition\").getOrCreate()\n","\n","# Step 2: Create DataFrame\n","patients_data = [\n","    (1, \"Daniel\", \"YFEV COUGH\"),\n","    (2, \"Alice\", \"\"),\n","    (3, \"Bob\", \"DIAB100 MYOP\"),\n","    (4, \"George\", \"ACNE DIAB100\"),\n","    (5, \"Alain\", \"DIAB201\"),\n","]\n","patients_columns = [\"patient_id\", \"patient_name\", \"conditions\"]\n","\n","patients_df = spark.createDataFrame(patients_data, patients_columns)\n","\n","# Step 3: Filter Rows Where conditions contain \"DIAB1\"\n","filtered_df = patients_df.filter(col(\"conditions\").rlike(r\"\\bDIAB1\\d*\\b\"))\n","\n","# Step 4: Select Required Columns\n","result_df = filtered_df.select(\"patient_id\", \"patient_name\", \"conditions\")\n","\n","# Step 5: Display Output\n","result_df.show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"d3d33543-511b-4cf8-a029-d4ae3905d6fd","normalized_state":"finished","queued_time":"2025-04-03T17:33:21.6425638Z","session_start_time":null,"execution_start_time":"2025-04-03T17:33:21.6436701Z","execution_finish_time":"2025-04-03T17:33:22.4977678Z","parent_msg_id":"808d7f60-ed62-4681-a513-38a8bcb69099"},"text/plain":"StatementMeta(, d3d33543-511b-4cf8-a029-d4ae3905d6fd, 15, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----------+------------+------------+\n|patient_id|patient_name|  conditions|\n+----------+------------+------------+\n|         3|         Bob|DIAB100 MYOP|\n|         4|      George|ACNE DIAB100|\n+----------+------------+------------+\n\n"]}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"77621513-627d-440b-b717-0b5057c90cf4"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","### **Steps**\n","1. **Create DataFrame for Patients**\n","2. **Register as SQL View**\n","3. **Run SQL Query Using `LIKE` or `REGEXP`**\n","4. **Return the Result**\n","\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"869c7c02-ddc3-421a-ba8c-133eff385f13"},{"cell_type":"code","source":["# Step 1: Register DataFrame as SQL View\n","patients_df.createOrReplaceTempView(\"Patients\")\n","\n","# Step 2: Run SQL Query\n","sql_query = \"\"\"\n","SELECT patient_id, patient_name, conditions\n","FROM Patients\n","WHERE conditions LIKE '%DIAB1%';\n","\"\"\"\n","\n","result_sql = spark.sql(sql_query)\n","\n","# Step 3: Display Output\n","result_sql.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"d3d33543-511b-4cf8-a029-d4ae3905d6fd","normalized_state":"finished","queued_time":"2025-04-03T17:33:21.689479Z","session_start_time":null,"execution_start_time":"2025-04-03T17:33:22.4997327Z","execution_finish_time":"2025-04-03T17:33:23.3179209Z","parent_msg_id":"0c9e1bf8-090f-47da-8670-786d7dd41515"},"text/plain":"StatementMeta(, d3d33543-511b-4cf8-a029-d4ae3905d6fd, 16, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+----------+------------+------------+\n|patient_id|patient_name|  conditions|\n+----------+------------+------------+\n|         3|         Bob|DIAB100 MYOP|\n|         4|      George|ACNE DIAB100|\n+----------+------------+------------+\n\n"]}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false}},"id":"760e18bb-c39f-4af4-ae90-a0d37b83c7fc"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","| Approach  | Method                      | Steps  |\n","|-----------|-----------------------------|--------|\n","| **Approach 1** | PySpark DataFrame API    | Uses **`rlike()`** to filter rows where `conditions` contain `\"DIAB1\"` |\n","| **Approach 2** | SQL Query in PySpark     | Uses **`REGEXP`** to find `\"DIAB1\"` pattern in the `conditions` column |\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8f207965-19bd-407e-ba8f-918f042c6a81"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}