{"cells":[{"cell_type":"markdown","source":["# **Consecutive Available Seats**\n","\n","## **Problem Statement**\n","We are given a cinema seat table like this:\n","\n","| seat_id | free |\n","|---------|------|\n","| 1       | 1    |\n","| 2       | 0    |\n","| 3       | 1    |\n","| 4       | 1    |\n","| 6       | 1    |\n","\n","We need to return the `seat_id`s of seats that are **part of at least two consecutive available seats (`free = 1`)**, ordered by `seat_id`.\n","\n","---\n","\n","## **Approach 1: PySpark DataFrame API**\n","\n","### **Steps**\n","1. Filter only the free seats (`free == 1`).\n","2. Use a **window** with `lag()` and `lead()` to compare with neighboring seat statuses.\n","3. Keep the rows where **either the previous or the next seat is also free**.\n","4. Return the `seat_id`s ordered by `seat_id`.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5dfb782e-4cbc-4f2e-8619-5f3c932c560f"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.window import Window\n","from pyspark.sql.functions import col, lag, lead\n","\n","# Initialize Spark\n","spark = SparkSession.builder.appName(\"CinemaSeats\").getOrCreate()\n","\n","# Sample Data\n","data = [\n","    (1, 1),  # seat_id, free\n","    (2, 0),\n","    (3, 1),\n","    (4, 1),\n","    (5, 0),\n","    (6, 1)\n","]\n","columns = [\"seat_id\", \"free\"]\n","\n","# Create DataFrame\n","cinema_df = spark.createDataFrame(data, columns)\n","\n","# Define Window\n","window = Window.orderBy(\"seat_id\")\n","\n","# Find seats with adjacent free seats\n","result_df = cinema_df.withColumn(\"prev_free\", lag(\"free\", 1).over(window)) \\\n","                     .withColumn(\"next_free\", lead(\"free\", 1).over(window)) \\\n","                     .filter((col(\"free\") == 1) & ((col(\"prev_free\") == 1) | (col(\"next_free\") == 1))) \\\n","                     .select(\"seat_id\") \\\n","                     .orderBy(\"seat_id\")\n","\n","result_df.show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"62b9881d-1c3c-4872-9341-4ea4610ccb9b","normalized_state":"finished","queued_time":"2025-04-11T17:45:02.4859572Z","session_start_time":null,"execution_start_time":"2025-04-11T17:45:02.4872415Z","execution_finish_time":"2025-04-11T17:45:03.339167Z","parent_msg_id":"1302c123-53b5-4397-a6b9-d697868b033a"},"text/plain":"StatementMeta(, 62b9881d-1c3c-4872-9341-4ea4610ccb9b, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-------+\n|seat_id|\n+-------+\n|      3|\n|      4|\n+-------+\n\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"31714587-766a-43a6-939d-d581e7004de5"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","\n","### **Steps**\n","1. Register the DataFrame as a temporary view.\n","2. Use SQL with `LAG()` and `LEAD()` window functions to find previous and next seat's availability.\n","3. Filter rows where seat is free and has a neighboring free seat.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8314db7d-52bf-4211-a05f-c4b786b8e6bf"},{"cell_type":"code","source":["cinema_df.createOrReplaceTempView(\"cinema\")\n","\n","spark.sql(\"\"\"\n","    SELECT seat_id\n","    FROM (\n","        SELECT seat_id,\n","               free,\n","               LAG(free) OVER (ORDER BY seat_id) AS prev_free,\n","               LEAD(free) OVER (ORDER BY seat_id) AS next_free\n","        FROM cinema\n","    ) t\n","    WHERE free = 1 AND (prev_free = 1 OR next_free = 1)\n","    ORDER BY seat_id\n","\"\"\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"62b9881d-1c3c-4872-9341-4ea4610ccb9b","normalized_state":"finished","queued_time":"2025-04-11T17:45:02.6169464Z","session_start_time":null,"execution_start_time":"2025-04-11T17:45:03.3413995Z","execution_finish_time":"2025-04-11T17:45:04.1569824Z","parent_msg_id":"e9af6646-ddd4-4f31-a209-e615c99d9623"},"text/plain":"StatementMeta(, 62b9881d-1c3c-4872-9341-4ea4610ccb9b, 14, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-------+\n|seat_id|\n+-------+\n|      3|\n|      4|\n+-------+\n\n"]}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6e17af8a-da3d-45c7-a68b-16afe8a781b7"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","\n","| Approach     | Method               | Highlights                                        |\n","|--------------|----------------------|---------------------------------------------------|\n","| Approach 1   | PySpark DataFrame API| Uses difference grouping for sequence blocks      |\n","| Approach 2   | SQL Query in PySpark | Uses window functions to detect adjacency         |"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9aa4ed25-ec97-4928-bd9b-a651de6de9ce"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}