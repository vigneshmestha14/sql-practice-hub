{"cells":[{"cell_type":"markdown","source":["# **Biggest Single Number**\n","\n","## **Problem Statement**\n","You are given a table `my_numbers` with a single column `num`. The column may contain duplicate values.  \n","Write a query to find the **largest number** that appears **only once** in the table.  \n","If no such number exists, return `null`.\n","\n","---\n","\n","### **Sample Input**\n","\n","| num |\n","|-----|\n","| 8   |\n","| 8   |\n","| 3   |\n","| 3   |\n","| 1   |\n","| 4   |\n","| 5   |\n","| 6   |\n","\n","### **Expected Output**\n","\n","| num |\n","|-----|\n","| 6   |\n","\n","---\n","\n","## **Approach 1: PySpark DataFrame API**\n","\n","### **Steps**\n","1. Group by `num` and count occurrences.\n","2. Filter for numbers that occur only once.\n","3. Take the maximum of those.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"68565903-c98b-4735-8412-5201d091970c"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, count, max as spark_max\n","\n","# Step 1: Initialize Spark\n","spark = SparkSession.builder.appName(\"BiggestSingleNumber\").getOrCreate()\n","\n","# Step 2: Sample Data\n","data = [\n","    (8,),\n","    (8,),\n","    (3,),\n","    (3,),\n","    (1,),\n","    (4,),\n","    (5,),\n","    (6,)\n","]\n","columns = [\"num\"]\n","\n","# Step 3: Create DataFrame\n","my_numbers_df = spark.createDataFrame(data, columns)\n","\n","# Step 4: Process Data\n","result_df = my_numbers_df.groupBy(\"num\") \\\n","                         .agg(count(\"*\").alias(\"cnt\")) \\\n","                         .filter(col(\"cnt\") == 1) \\\n","                         .agg(spark_max(\"num\").alias(\"num\"))\n","\n","# Step 5: Display Result\n","result_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"9dc5f343-c28a-42ab-beef-42af4301a688","normalized_state":"finished","queued_time":"2025-04-12T17:20:15.2361878Z","session_start_time":null,"execution_start_time":"2025-04-12T17:20:15.2374056Z","execution_finish_time":"2025-04-12T17:20:16.7152654Z","parent_msg_id":"ada7db46-091b-4e31-b625-aada6f5e03af"},"text/plain":"StatementMeta(, 9dc5f343-c28a-42ab-beef-42af4301a688, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+\n|num|\n+---+\n|  6|\n+---+\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6d7356eb-0b50-4165-9f7e-f3a65e6abe8e"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","\n","### **Steps**\n","1. Group numbers and count their frequencies.\n","2. Select only those with count = 1.\n","3. Get the max of that filtered list.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a118fbde-30df-478f-8d46-0ea6420be859"},{"cell_type":"code","source":["my_numbers_df.createOrReplaceTempView(\"my_numbers\")\n","\n","spark.sql(\"\"\"\n","    SELECT MAX(num) AS num\n","    FROM (\n","        SELECT num\n","        FROM my_numbers\n","        GROUP BY num\n","        HAVING COUNT(*) = 1\n","    ) AS singles\n","\"\"\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"9dc5f343-c28a-42ab-beef-42af4301a688","normalized_state":"finished","queued_time":"2025-04-12T17:20:15.3207589Z","session_start_time":null,"execution_start_time":"2025-04-12T17:20:16.7172145Z","execution_finish_time":"2025-04-12T17:20:18.1999481Z","parent_msg_id":"42807e10-c25b-4b6f-9d19-84706c3a387c"},"text/plain":"StatementMeta(, 9dc5f343-c28a-42ab-beef-42af4301a688, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+\n|num|\n+---+\n|  6|\n+---+\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2fece104-9763-43bf-b5b2-6ced6eb4507f"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","\n","| Approach     | Method               | Highlights                                        |\n","|--------------|----------------------|---------------------------------------------------|\n","| Approach 1   | PySpark DataFrame API| GroupBy with count, filter, then max              |\n","| Approach 2   | SQL Query in PySpark | Clean SQL using `GROUP BY`, `HAVING`, and `MAX()` |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c7d29874-7ffc-4e40-9216-e936f2fab639"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}