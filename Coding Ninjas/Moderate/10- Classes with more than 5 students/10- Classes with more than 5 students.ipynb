{"cells":[{"cell_type":"markdown","source":["# **Classes with More than 5 students**\n","\n","## **Problem Statement**\n","You are given a table `courses` with the following structure:\n","\n","| Column Name | Type   |\n","|-------------|--------|\n","| student     | string |\n","| class       | string |\n","\n","Write a query to **list all classes** that have **five or more students** enrolled.\n","\n","---\n","\n","### **Example**\n","\n","#### **Input Table: courses**\n","| student | class    |\n","|---------|----------|\n","| A       | Math     |\n","| B       | English  |\n","| C       | Math     |\n","| D       | Biology  |\n","| E       | Math     |\n","| F       | Computer |\n","| G       | Math     |\n","| H       | Math     |\n","| I       | Math     |\n","\n","#### **Expected Output**\n","| class |\n","|--------|\n","| Math   |\n","\n","---\n","\n","## **Approach 1: PySpark DataFrame API**\n","\n","### **Steps**\n","1. Create a DataFrame.\n","2. Group by class and count students.\n","3. Filter where count is >= 5.\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2fe6dc8e-4872-4e40-bb2d-b0cdf863bec9"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, count\n","\n","# Step 1: Initialize Spark\n","spark = SparkSession.builder.appName(\"Courses\").getOrCreate()\n","\n","# Step 2: Create DataFrame\n","data = [\n","    (\"A\", \"Math\"), (\"B\", \"English\"), (\"C\", \"Math\"),\n","    (\"D\", \"Biology\"), (\"E\", \"Math\"), (\"F\", \"Computer\"),\n","    (\"G\", \"Math\"), (\"H\", \"Math\"), (\"I\", \"Math\")\n","]\n","columns = [\"student\", \"class\"]\n","df = spark.createDataFrame(data, columns)\n","\n","# Step 3: Group by class and count students\n","result = df.groupBy(\"class\").agg(count(\"student\").alias(\"num_students\"))\n","\n","# Step 4: Filter classes with >= 5 students\n","result.filter(col(\"num_students\") >= 5).select(\"class\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"c33e8b16-1712-4e07-bcbf-202f3fbfa08f","normalized_state":"finished","queued_time":"2025-04-06T16:54:18.6513757Z","session_start_time":null,"execution_start_time":"2025-04-06T16:54:18.652661Z","execution_finish_time":"2025-04-06T16:54:19.4666816Z","parent_msg_id":"562bc4f5-8e45-4395-92c7-8b5cb700e0bb"},"text/plain":"StatementMeta(, c33e8b16-1712-4e07-bcbf-202f3fbfa08f, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+\n|class|\n+-----+\n| Math|\n+-----+\n\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1fe4cfd5-f311-4bef-8ae7-ba5bdf295483"},{"cell_type":"markdown","source":["---\n","\n","## **Approach 2: SQL Query in PySpark**\n","\n","### **Steps**\n","1. Register DataFrame as a SQL temp view.\n","2. Use GROUP BY and HAVING to filter classes.\n","\n","\n","### **Code**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d2eabea5-2830-4ddc-85ca-0dfc2ccbf9c6"},{"cell_type":"code","source":["\n","df.createOrReplaceTempView(\"courses\")\n","\n","sql_result = spark.sql(\"\"\"\n","    SELECT class\n","    FROM courses\n","    GROUP BY class\n","    HAVING COUNT(student) >= 5\n","\"\"\")\n","\n","sql_result.show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"c33e8b16-1712-4e07-bcbf-202f3fbfa08f","normalized_state":"finished","queued_time":"2025-04-06T16:54:18.688856Z","session_start_time":null,"execution_start_time":"2025-04-06T16:54:19.4686299Z","execution_finish_time":"2025-04-06T16:54:20.2469018Z","parent_msg_id":"2f729324-b51a-4a2d-a2af-abc32a76abf2"},"text/plain":"StatementMeta(, c33e8b16-1712-4e07-bcbf-202f3fbfa08f, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----+\n|class|\n+-----+\n| Math|\n+-----+\n\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9956b2ac-dcff-461a-af25-dadcd848b794"},{"cell_type":"markdown","source":["---\n","\n","## **Summary**\n","\n","| Approach         | Method                | Key Function      |\n","|------------------|------------------------|--------------------|\n","| **Approach 1**   | PySpark DataFrame API  | `groupBy`, `count` |\n","| **Approach 2**   | SQL in PySpark         | `GROUP BY`, `HAVING` |"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e335f2a7-dc59-48c6-8dca-2796a2294631"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}